{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tight-wildlife",
   "metadata": {},
   "source": [
    "Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-appliance",
   "metadata": {},
   "source": [
    "Labpartner(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements go here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-carnival",
   "metadata": {},
   "source": [
    "# Class 13.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-injury",
   "metadata": {},
   "source": [
    "# Warmups 13.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d30bae-583b-43f6-a8dd-df1a22cb9bc4",
   "metadata": {},
   "source": [
    "**W.0** Install scikitlearn if you don't have it already. It should come standard with your install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae75bfc2-4fac-4efa-bdf1-9b485c0af8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have it this will work:\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-north",
   "metadata": {},
   "source": [
    "**W.1 Guessing game** Generate a random number between 1 and 9 (including 1 and 9). Ask the user to guess the number, then tell them whether they guessed too low, too high, or exactly right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder of how user input works:\n",
    "name = input(\"Give me your name: \")\n",
    "print(\"Your name is \" + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3021556-42f1-451e-96e1-49d511b68a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d2d6b55-b924-43c0-af5a-14d1366dd7fb",
   "metadata": {},
   "source": [
    "**W.2** Modify the game: \n",
    "- Keep the game going until the user types “exit”\n",
    "- Keep track of how many guesses the user has taken, and when the game ends, print this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2ac46-de6e-4ef0-8b6a-356f33079545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "weird-james",
   "metadata": {},
   "source": [
    "# Lecture 13.1\n",
    "\n",
    "## Agenda:\n",
    "- Machine Learning in Scikit learn\n",
    "- We are starting the Datacamp machine learning module. They cover some of the things in the scikit-learn package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-material",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Machine Learning has emerged as an important tool accross the scientific diciplines and in many business applications. The most commonly used package for machine learning is scikit-learn, which we will play around with this week.\n",
    "\n",
    "There are a number of types of machine learning algorithms, aka \"estimators\". A useful flowchart:\n",
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/\n",
    "\n",
    "These can be divided up into:\n",
    "\n",
    "1) Regression. This involves finding the best fit parameters for some model, like with did with linear models.\n",
    "\n",
    "2) Clustering, which groups data by some similarity criterion (e.g., these data points are grass, these are trees, and these are water because of their spectral data differences). See https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py\n",
    "\n",
    "3) Dimensionality reduction, which breaks data, often timesries data, into principle components. For example if we were looking at a temperature timeseries, we might get as components an annual cycle, a daily cycle, and a multi-year cycle corresponding to ENSO (El Nino - Southern Oscillation), etc.\n",
    "\n",
    "4) Classification. This uses labeled data to make preditions about what will happen in places you don't have data, for example in this area it is expected to see large green birds and not small red birds, and in another area it is expected to see both types. We will focus on this today.\n",
    "\n",
    "See also: https://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-instrumentation",
   "metadata": {},
   "source": [
    "## Classification example from scikit-learn\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-exhibition",
   "metadata": {},
   "source": [
    "Here is the whole code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83712d33-80ae-4d3b-82ed-942257b92f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(gamma=2, C=1, random_state=42),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "    ),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
    "    AdaBoostClassifier(algorithm=\"SAMME\", random_state=42),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1\n",
    ")\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [\n",
    "    make_moons(noise=0.3, random_state=0),\n",
    "    make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "    linearly_separable,\n",
    "]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=42\n",
    "    )\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "    # Plot the testing points\n",
    "    ax.scatter(\n",
    "        X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors=\"k\"\n",
    "    )\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        DecisionBoundaryDisplay.from_estimator(\n",
    "            clf, X, cmap=cm, alpha=0.8, ax=ax, eps=0.5\n",
    "        )\n",
    "\n",
    "        # Plot the training points\n",
    "        ax.scatter(\n",
    "            X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\"\n",
    "        )\n",
    "        # Plot the testing points\n",
    "        ax.scatter(\n",
    "            X_test[:, 0],\n",
    "            X_test[:, 1],\n",
    "            c=y_test,\n",
    "            cmap=cm_bright,\n",
    "            edgecolors=\"k\",\n",
    "            alpha=0.6,\n",
    "        )\n",
    "\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        ax.text(\n",
    "            x_max - 0.3,\n",
    "            y_min + 0.3,\n",
    "            (\"%.2f\" % score).lstrip(\"0\"),\n",
    "            size=15,\n",
    "            horizontalalignment=\"right\",\n",
    "        )\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e0dff8-9a47-4e2c-8342-c017d249a251",
   "metadata": {},
   "source": [
    "If you want to check out the lab from the previous year when I went through this step by step, it's in the old class: https://github.com/chsharrison/IntroSciComp_S2021/blob/main/Class_materials/Lab13.1_machine_learning_adv.ipynb\n",
    "and\n",
    "https://github.com/chsharrison/IntroSciComp_S2021/blob/main/Class_materials/Lab13.2_machine_learning_adv.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3dc77a-2ca9-40ff-9f48-34ae16ad4e6c",
   "metadata": {},
   "source": [
    "# Lab 13.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b2665a-c014-4cd1-aba7-b15022fa7ef0",
   "metadata": {},
   "source": [
    "#### E.0 Complete the previous labs if you are behind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e31b762-f054-4d70-bd58-58a66711f453",
   "metadata": {},
   "source": [
    "#### E.1 Complete Ch 1-2 of \"Supervised Learning with scikit-learn\". Don't forget to turn in your scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5499c6-7c80-42e7-9f64-9a00e206893a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30d82416-9655-4024-ac9d-fd49e12c6182",
   "metadata": {},
   "source": [
    "**Notes** Make notes for yourself on progamming tecniques and commands you learned in the this week, including examples, comments and explainitory text. You can do this here or in a separate notebook that you link to here. Basically, you are making a cheat sheet for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d1c53-65da-4043-a168-cec52ea76ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ded98577-1d87-4f3e-a630-6074f646c977",
   "metadata": {},
   "source": [
    "#### E.2 Work on your final project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74617577-1e8c-41cf-afd5-ee671021c54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
