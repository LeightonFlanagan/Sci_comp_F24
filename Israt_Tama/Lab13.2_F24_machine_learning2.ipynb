{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tight-wildlife",
   "metadata": {},
   "source": [
    "Name: Israt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-appliance",
   "metadata": {},
   "source": [
    "Labpartner(s): Fahmida, Zach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements go here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-carnival",
   "metadata": {},
   "source": [
    "# Class 13.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-injury",
   "metadata": {},
   "source": [
    "# Warmups 13.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-north",
   "metadata": {},
   "source": [
    "**W.1 Pandas Practice** \n",
    "\n",
    "Create a pandas series from each of the items below: a list, numpy and a dictionary\n",
    "\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "\n",
    "myarr = np.arange(26)\n",
    "\n",
    "mydict = dict(zip(mylist, myarr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "inner-finish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series from List:\n",
      "0     a\n",
      "1     b\n",
      "2     c\n",
      "3     e\n",
      "4     d\n",
      "5     f\n",
      "6     g\n",
      "7     h\n",
      "8     i\n",
      "9     j\n",
      "10    k\n",
      "11    l\n",
      "12    m\n",
      "13    n\n",
      "14    o\n",
      "15    p\n",
      "16    q\n",
      "17    r\n",
      "18    s\n",
      "19    t\n",
      "20    u\n",
      "21    v\n",
      "22    w\n",
      "23    x\n",
      "24    y\n",
      "25    z\n",
      "dtype: object\n",
      "\n",
      "Series from Numpy Array:\n",
      "0      0\n",
      "1      1\n",
      "2      2\n",
      "3      3\n",
      "4      4\n",
      "5      5\n",
      "6      6\n",
      "7      7\n",
      "8      8\n",
      "9      9\n",
      "10    10\n",
      "11    11\n",
      "12    12\n",
      "13    13\n",
      "14    14\n",
      "15    15\n",
      "16    16\n",
      "17    17\n",
      "18    18\n",
      "19    19\n",
      "20    20\n",
      "21    21\n",
      "22    22\n",
      "23    23\n",
      "24    24\n",
      "25    25\n",
      "dtype: int32\n",
      "\n",
      "Series from Dictionary:\n",
      "a     0\n",
      "b     1\n",
      "c     2\n",
      "e     3\n",
      "d     4\n",
      "f     5\n",
      "g     6\n",
      "h     7\n",
      "i     8\n",
      "j     9\n",
      "k    10\n",
      "l    11\n",
      "m    12\n",
      "n    13\n",
      "o    14\n",
      "p    15\n",
      "q    16\n",
      "r    17\n",
      "s    18\n",
      "t    19\n",
      "u    20\n",
      "v    21\n",
      "w    22\n",
      "x    23\n",
      "y    24\n",
      "z    25\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating the list, numpy array, and dictionary\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "\n",
    "# Creating a pandas series from each\n",
    "series_from_list = pd.Series(mylist)\n",
    "series_from_array = pd.Series(myarr)\n",
    "series_from_dict = pd.Series(mydict)\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Series from List:\")\n",
    "print(series_from_list)\n",
    "\n",
    "print(\"\\nSeries from Numpy Array:\")\n",
    "print(series_from_array)\n",
    "\n",
    "print(\"\\nSeries from Dictionary:\")\n",
    "print(series_from_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d83b5-0624-45ff-89d4-03d8ee7ac8f1",
   "metadata": {},
   "source": [
    "**W.2 Pandas Practice con** \n",
    "\n",
    "Convert the series you just created into a dataframe with its index as another column on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df2ac46-de6e-4ef0-8b6a-356f33079545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from List:\n",
      "    index Value\n",
      "0       0     a\n",
      "1       1     b\n",
      "2       2     c\n",
      "3       3     e\n",
      "4       4     d\n",
      "5       5     f\n",
      "6       6     g\n",
      "7       7     h\n",
      "8       8     i\n",
      "9       9     j\n",
      "10     10     k\n",
      "11     11     l\n",
      "12     12     m\n",
      "13     13     n\n",
      "14     14     o\n",
      "15     15     p\n",
      "16     16     q\n",
      "17     17     r\n",
      "18     18     s\n",
      "19     19     t\n",
      "20     20     u\n",
      "21     21     v\n",
      "22     22     w\n",
      "23     23     x\n",
      "24     24     y\n",
      "25     25     z\n",
      "\n",
      "DataFrame from Numpy Array:\n",
      "    index  Value\n",
      "0       0      0\n",
      "1       1      1\n",
      "2       2      2\n",
      "3       3      3\n",
      "4       4      4\n",
      "5       5      5\n",
      "6       6      6\n",
      "7       7      7\n",
      "8       8      8\n",
      "9       9      9\n",
      "10     10     10\n",
      "11     11     11\n",
      "12     12     12\n",
      "13     13     13\n",
      "14     14     14\n",
      "15     15     15\n",
      "16     16     16\n",
      "17     17     17\n",
      "18     18     18\n",
      "19     19     19\n",
      "20     20     20\n",
      "21     21     21\n",
      "22     22     22\n",
      "23     23     23\n",
      "24     24     24\n",
      "25     25     25\n",
      "\n",
      "DataFrame from Dictionary:\n",
      "   index  Value\n",
      "0      a      0\n",
      "1      b      1\n",
      "2      c      2\n",
      "3      e      3\n",
      "4      d      4\n",
      "5      f      5\n",
      "6      g      6\n",
      "7      h      7\n",
      "8      i      8\n",
      "9      j      9\n",
      "10     k     10\n",
      "11     l     11\n",
      "12     m     12\n",
      "13     n     13\n",
      "14     o     14\n",
      "15     p     15\n",
      "16     q     16\n",
      "17     r     17\n",
      "18     s     18\n",
      "19     t     19\n",
      "20     u     20\n",
      "21     v     21\n",
      "22     w     22\n",
      "23     x     23\n",
      "24     y     24\n",
      "25     z     25\n"
     ]
    }
   ],
   "source": [
    "# Convert each Series to DataFrame and include index as a column\n",
    "df_from_list = series_from_list.reset_index(name='Value')\n",
    "df_from_array = series_from_array.reset_index(name='Value')\n",
    "df_from_dict = series_from_dict.reset_index(name='Value')\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"DataFrame from List:\")\n",
    "print(df_from_list)\n",
    "\n",
    "print(\"\\nDataFrame from Numpy Array:\")\n",
    "print(df_from_array)\n",
    "\n",
    "print(\"\\nDataFrame from Dictionary:\")\n",
    "print(df_from_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74a1dc-8f91-455c-a5d6-9c16aa9df080",
   "metadata": {},
   "source": [
    "**W.3 Pandas Practice con** \n",
    "\n",
    "Combine two series to form a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59e7be0c-c1af-4cf4-9952-ab55c6647222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Letter  Number\n",
      "0       a       0\n",
      "1       b       1\n",
      "2       c       2\n",
      "3       e       3\n",
      "4       d       4\n",
      "5       f       5\n",
      "6       g       6\n",
      "7       h       7\n",
      "8       i       8\n",
      "9       j       9\n",
      "10      k      10\n",
      "11      l      11\n",
      "12      m      12\n",
      "13      n      13\n",
      "14      o      14\n",
      "15      p      15\n",
      "16      q      16\n",
      "17      r      17\n",
      "18      s      18\n",
      "19      t      19\n",
      "20      u      20\n",
      "21      v      21\n",
      "22      w      22\n",
      "23      x      23\n",
      "24      y      24\n",
      "25      z      25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating the list and numpy array\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "\n",
    "# Creating pandas Series from the list and array\n",
    "series_from_list = pd.Series(mylist, name='Letter')\n",
    "series_from_array = pd.Series(myarr, name='Number')\n",
    "\n",
    "# Combine the two Series into a DataFrame\n",
    "df_combined = pd.DataFrame({'Letter': series_from_list, 'Number': series_from_array})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df53b8c5-06cd-40bd-a7cd-9f99cbeff8f5",
   "metadata": {},
   "source": [
    "**W.4 Pandas Practice con**\n",
    "\n",
    "Compute the minimum, 25th percentile, median, 75th, and maximum of the following series:\n",
    "\n",
    "ser = pd.Series(np.random.normal(10, 5, 25))\n",
    "\n",
    "What kind of distribution is this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe1b40-c864-458b-8423-ee4bbd1cd19c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "weird-james",
   "metadata": {},
   "source": [
    "# Lecture 13.1\n",
    "\n",
    "## Agenda:\n",
    "- Machine Learning in Scikit learn Ch 3-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3dc77a-2ca9-40ff-9f48-34ae16ad4e6c",
   "metadata": {},
   "source": [
    "# Lab 13.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b2665a-c014-4cd1-aba7-b15022fa7ef0",
   "metadata": {},
   "source": [
    "#### E.0 Complete the previous labs if you are behind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e31b762-f054-4d70-bd58-58a66711f453",
   "metadata": {},
   "source": [
    "#### E.1 Complete Ch 3-4 of \"Supervised Learning with scikit-learn\". Don't forget to turn in your scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5499c6-7c80-42e7-9f64-9a00e206893a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30d82416-9655-4024-ac9d-fd49e12c6182",
   "metadata": {},
   "source": [
    "**Notes** Make notes for yourself on progamming tecniques and commands you learned in the this week, including examples, comments and explainitory text. You can do this here or in a separate notebook that you link to here. Basically, you are making a cheat sheet for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d1c53-65da-4043-a168-cec52ea76ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chapater 03: part 01: How good the model is\n",
    "# Import confusion matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "Chapter 03: part 02: building a logistic regression model\n",
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(y_pred_probs[:10])\n",
    "\n",
    "# The ROC curve \n",
    "# Import roc_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# Plot tpr against fpr\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Diabetes Prediction')\n",
    "plt.show()\n",
    "\n",
    "# ROC AUC\n",
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate roc_auc_score\n",
    "print(roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate the classification report\n",
    "\n",
    "Chapter 03: part 03: Hyper parameter tuning\n",
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\"alpha\": np.linspace(0.0001, 1, 10)}\n",
    "\n",
    "# Instantiate lasso_cv\n",
    "lasso_cv = RandomizedSearchCV(lasso, param_grid, cv=kf)\n",
    "\n",
    "# Fit to the training data\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "print(\"Tuned lasso paramaters: {}\".format(lasso_cv.best_params_))\n",
    "print(\"Tuned lasso score: {}\".format(lasso_cv.best_score_))\n",
    "\n",
    "# Hyprer parameter tuning\n",
    "# Create the parameter space\n",
    "params = {\"penalty\": [\"l1\", \"l2\"],\n",
    "         \"tol\": np.linspace(0.0001, 1.0, 50),\n",
    "         \"C\": np.linspace(0.1, 1.0, 50),\n",
    "         \"class_weight\": [\"balanced\", {0:0.8, 1:0.2}]}\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "logreg_cv = RandomizedSearchCV(logreg, params, cv=kf)\n",
    "\n",
    "# Fit the data to the model\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Best Accuracy Score: {}\".format(logreg_cv.best_score_))\n",
    "\n",
    "Chapter 04: part 01: creating dummy variables\n",
    "# Create music_dummies\n",
    "music_dummies = pd.get_dummies(music_df,drop_first=True)\n",
    "\n",
    "# Print the new DataFrame's shape\n",
    "print(\"Shape of music_dummies: {}\".format(music_dummies.shape))\n",
    "\n",
    "# Regression with categorical features\n",
    "# Create X and y\n",
    "X = music_dummies.drop(columns=[\"popularity\"], errors=\"ignore\") \n",
    "y = music_df[\"popularity\"]\n",
    "\n",
    "# Instantiate a ridge model\n",
    "ridge = Ridge(alpha=0.2)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(-scores)\n",
    "print(\"Average RMSE: {}\".format(np.mean(rmse)))\n",
    "print(\"Standard Deviation of the target array: {}\".format(np.std(y)))\n",
    "\n",
    "#chapter 04: part 02: dropping missing values\n",
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())\n",
    "# dropping missing data\n",
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())\n",
    "\n",
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\",\"loudness\", \"liveness\", \"tempo\"])\n",
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())\n",
    "\n",
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n",
    "\n",
    "# Convert genre to a binary feature\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "\n",
    "print(music_df.isna().sum().sort_values())\n",
    "print(\"Shape of the `music_df`: {}\".format(music_df.shape))\n",
    "\n",
    "# pipeline for genre preparation 1\n",
    "# Import modules\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Instantiate an imputer\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Instantiate a knn model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Build steps for the pipeline\n",
    "steps = [(\"imputer\", imputer), \n",
    "         (\"knn\", knn)]\n",
    "\n",
    "# Pipeline for genre prediction 2\n",
    "steps = [(\"imputer\", imp_mean),\n",
    "        (\"knn\", knn)]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "Chapter 04: part 03: centering and scaling for regression\n",
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create pipeline steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"lasso\", Lasso(alpha=0.5))]\n",
    "\n",
    "# Instantiate the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate and print R-squared\n",
    "print(pipeline.score(X_test, y_test))\n",
    "# Build the steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"logreg\", LogisticRegression())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create the parameter space\n",
    "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "# Instantiate the grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "# Fit to the training data\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)\n",
    "\n",
    "#Chapter 04: Part 04: Visualizing regression model performance\n",
    "models = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1), \"Lasso\": Lasso(alpha=0.1)}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "  \n",
    "  # Append the results\n",
    "  results.append(cv_scores)\n",
    "\n",
    "# Create a box plot of the results\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()\n",
    "\n",
    "# Predicting on the test set\n",
    "# Import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for name, model in models.items():\n",
    "  \n",
    "  # Fit the model to the training data\n",
    "  model.fit(X_train_scaled, y_train)\n",
    "  \n",
    "  # Make predictions on the test set\n",
    "  y_pred = model.predict(X_test_scaled)\n",
    "  \n",
    "  # Calculate the test_rmse\n",
    "  test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "  print(\"{} Test Set RMSE: {}\".format(name, test_rmse))\n",
    "\n",
    "# Create models dictionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \"KNN\": KNeighborsClassifier(), \n",
    "          \"Decision Tree Classifier\": DecisionTreeClassifier()}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  \n",
    "  # Instantiate a KFold object\n",
    "  kf = KFold(n_splits=6, random_state=12, shuffle=True)\n",
    "  \n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "  results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()\n",
    "\n",
    "# Pipeline for predicting song's popolarity\n",
    "# Create steps\n",
    "steps = [(\"imp_mean\", SimpleImputer()), \n",
    "         (\"scaler\", StandardScaler()), \n",
    "         (\"logreg\", LogisticRegression())]\n",
    "\n",
    "# Set up pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "params = {\"logreg__solver\": [\"newton-cg\", \"saga\", \"lbfgs\"],\n",
    "         \"logreg__C\": np.linspace(0.001, 1.0, 10)}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "tuning = GridSearchCV(pipeline, param_grid=params, cv=5)\n",
    "tuning.fit(X_train, y_train)\n",
    "y_pred = tuning.predict(X_test)\n",
    "\n",
    "# Compute and print performance\n",
    "print(\"Tuned Logistic Regression Parameters: {}, Accuracy: {}\".format(tuning.best_params_, tuning.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded98577-1d87-4f3e-a630-6074f646c977",
   "metadata": {},
   "source": [
    "#### E.2 Work on your final project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74617577-1e8c-41cf-afd5-ee671021c54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
