{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cooked-impact",
   "metadata": {},
   "source": [
    "Name: Israt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-drunk",
   "metadata": {},
   "source": [
    "Labpartner(s): Fahmida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "statistical-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements go here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-tribute",
   "metadata": {},
   "source": [
    "# Class 8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834986df-a157-45a3-8679-12e793fe2c47",
   "metadata": {},
   "source": [
    "Today we are presenting movies and Karen will tell us all about how to use AI. The homework is to work on your proposals and/or do some extra datacamp related to your research needs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-tradition",
   "metadata": {},
   "source": [
    "**W.1** Write a function that takes a list and returns a new list that contains all the elements of the first list minus all the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "champion-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(input_list):\n",
    "    seen = set()  # A set to keep track of elements that have already been encountered\n",
    "    result = []  # A list to store the unique elements\n",
    "\n",
    "    for item in input_list:\n",
    "        if item not in seen:\n",
    "            result.append(item)  # Add to result if not already in seen\n",
    "            seen.add(item)  # Mark as seen\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecd8a04-8bae-404d-87b8-0e0cf0bc7a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list=[ 2, 4, 5, 5, 6, 7, 8]\n",
    "remove_duplicates(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-irish",
   "metadata": {},
   "source": [
    "# Lecture 8.1\n",
    "\n",
    "### Agenda:\n",
    "\n",
    "- Questions\n",
    "- Show us your movies\n",
    "- Effective use of AI in programming and writing (Karen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-hobby",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be69581e-ee02-4aa7-a18e-74c2d61cc1c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "working-lottery",
   "metadata": {},
   "source": [
    "# Lab 8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba70db-1894-44eb-9688-5380d60b34f6",
   "metadata": {},
   "source": [
    "**E.0** Complete the previous labs if you are behind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-variable",
   "metadata": {},
   "source": [
    "**E.1** Work on your research proposal and/or do an optional course in datacamp that would be useful for your research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-strap",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "computational-child",
   "metadata": {},
   "source": [
    "**E.2** Make notes for yourself on progamming tecniques and commands you learned in the this week, including examples, comments and explainitory text. You can do this here or in a separate notebook that you link to here. Basically, you are making a cheat sheet for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53334f1-6e12-4ef1-9465-8de2ceb2f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating mean and median using numpy\n",
    "Datacamp Chapter 01: Part 02\n",
    "Import numpy with alias np\r\n",
    "import numpy as np\r\n",
    "# Subset country for USA: usa_consumption\r\n",
    "usa_consumption = food_consumption[food_consumption[\"country\"]==\"USA\r\n",
    "\r\n",
    "# Calculate mean consumption in USA\r\n",
    "print(np.mean(usa_consumption[\"consumptio]))\r\n",
    "\r\n",
    "# Calculate median consumption in USA\r\n",
    "print(np.median(usa_consumption[\"consum\n",
    "\n",
    "# mean vs Median\n",
    "              # Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Subset for food_category equals rice\n",
    "rice_consumption = food_consumption[food_consumption[\"food_category\"]==\"rice\"]\n",
    "\n",
    "# Histogram of co2_emission for rice and show plot\n",
    "rice_consumption[\"co2_emission\"].hist()\n",
    "plt.show()\n",
    "                # Subset for food_category equals rice\n",
    "rice_consumption = food_consumption[food_consumption['food_category'] == 'rice']\n",
    "\n",
    "# Calculate mean and median of co2_emission with .agg()\n",
    "print(rice_consumption[\"co2_emission\"].agg([np.mean, np.median]))ption\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932d25b-624e-4115-9b6f-3b1ade4471a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter one : part 03: Variance and Standard deviation\n",
    "# Print variance and sd of co2_emission for each food_category\n",
    "print(food_consumption.groupby(\"food_category\")[\"co2_emission\"].agg([np.std,np.var]))\n",
    "\n",
    "# Create histogram of co2_emission for food_category 'beef'\n",
    "food_consumption[food_consumption[\"food_category\"]==\"beef\"]['co2_emission'].hist()\n",
    "plt.show()\n",
    "\n",
    "# Create histogram of co2_emission for food_category 'eggs'\n",
    "food_consumption[food_consumption[\"food_category\"]==\"eggs\"]['co2_emission'].hist()\n",
    "plt.show()\n",
    "\n",
    "# calculaating the quantiles\n",
    "# Calculate the deciles of co2_emission\n",
    "print(np.quantile(food_consumption[\"co2_emission\"], np.linspace(0,1,11)))\n",
    "\n",
    "# calculating the outliers\n",
    "# Calculate total co2_emission per country: emissions_by_country\n",
    "emissions_by_country = food_consumption.groupby('country')['co2_emission'].sum()\n",
    "\n",
    "# Compute the first and third quantiles and IQR of emissions_by_country\n",
    "q1 = np.quantile(emissions_by_country, 0.25)\n",
    "q3 = np.quantile(emissions_by_country, 0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Calculate the lower and upper cutoffs for outliers\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "\n",
    "# Subset emissions_by_country to find outliers\n",
    "outliers =emissions_by_country[(emissions_by_country<lower)|(emissions_by_country>upper)]\n",
    "print(outliers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
